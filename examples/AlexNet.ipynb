{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from architectures.AlexNet import *\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 1\n",
    "\n",
    "IMG_SIZE = 32\n",
    "N_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256), \n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # mean activity over the training set from the paper\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The dataset is no longer publicly accessible. You need to download the archives externally and place them in the root directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e9fa14ab86ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# download and create datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_dataset = datasets.ImageNet(root='./imagenet_data', \n\u001b[0m\u001b[1;32m      3\u001b[0m                                \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                download=True)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, download, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                    \u001b[0;34m\"download the archives externally and place them in the root \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                    \"directory.\")\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             msg = (\"The use of the download flag is deprecated, since the dataset \"\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The dataset is no longer publicly accessible. You need to download the archives externally and place them in the root directory."
     ]
    }
   ],
   "source": [
    "# download and create datasets\n",
    "train_dataset = datasets.ImageNet(root='./imagenet_data', \n",
    "                               split='train', \n",
    "                               transform=transforms,\n",
    "                               download=True)\n",
    "\n",
    "valid_dataset = datasets.ImageNet(root='./imagenet_data', \n",
    "                               split='val', \n",
    "                               transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = nn.AvgPool2d(kernel_size = 2, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [\n",
    "        [1, 1, 1, 1],\n",
    "        [2, 2, 2, 2],\n",
    "        [3, 3, 3, 3],\n",
    "        [4, 4, 4, 4]\n",
    "    ],\n",
    "    [\n",
    "        [10, 10, 10, 10],\n",
    "        [20, 20, 20, 20],\n",
    "        [30, 30, 30, 30],\n",
    "        [40, 40, 40, 40]\n",
    "    ]\n",
    "], dtype=float).view((1,2,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5000,  1.5000,  1.5000],\n",
       "          [ 2.5000,  2.5000,  2.5000],\n",
       "          [ 3.5000,  3.5000,  3.5000]],\n",
       "\n",
       "         [[15.0000, 15.0000, 15.0000],\n",
       "          [25.0000, 25.0000, 25.0000],\n",
       "          [35.0000, 35.0000, 35.0000]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 4, 4])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x**2).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5935,  0.5935,  0.5935,  0.5935],\n",
       "          [ 1.1803,  1.1803,  1.1803,  1.1803],\n",
       "          [ 1.7540,  1.7540,  1.7540,  1.7540],\n",
       "          [ 2.3088,  2.3088,  2.3088,  2.3088]],\n",
       "\n",
       "         [[ 5.9348,  5.9348,  5.9348,  5.9348],\n",
       "          [11.8028, 11.8028, 11.8028, 11.8028],\n",
       "          [17.5400, 17.5400, 17.5400, 17.5400],\n",
       "          [23.0880, 23.0880, 23.0880, 23.0880]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = LocalResponceNorm(n=2,across_channels=True)\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5946,  0.5946,  0.5946,  0.5946],\n",
       "          [ 1.1890,  1.1890,  1.1890,  1.1890],\n",
       "          [ 1.7836,  1.7835,  1.7835,  1.7836],\n",
       "          [ 2.3781,  2.3780,  2.3780,  2.3781]],\n",
       "\n",
       "         [[ 5.9088,  5.8966,  5.8966,  5.9088],\n",
       "          [11.7340, 11.6824, 11.6824, 11.7340],\n",
       "          [17.6010, 17.5236, 17.5236, 17.6010],\n",
       "          [23.4784, 23.3785, 23.3785, 23.4784]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = LocalResponceNorm(n=5,across_channels=False)\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5942,  0.5942,  0.5942,  0.5942],\n",
       "          [ 1.1856,  1.1856,  1.1856,  1.1856],\n",
       "          [ 1.7717,  1.7717,  1.7717,  1.7717],\n",
       "          [ 2.3500,  2.3500,  2.3500,  2.3500]],\n",
       "\n",
       "         [[ 5.9415,  5.9415,  5.9415,  5.9415],\n",
       "          [11.8562, 11.8562, 11.8562, 11.8562],\n",
       "          [17.7175, 17.7175, 17.7175, 17.7175],\n",
       "          [23.4999, 23.4999, 23.4999, 23.4999]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LocalResponseNorm(5, k=2, alpha=1e-04, beta=0.75)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
